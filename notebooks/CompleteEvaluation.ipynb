{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Disf + TBM Segmentation\n",
    "---\n",
    "Applying DISF as pre-segmentation method and TBM as superpixel classifier to obtain segmentation on FoxP3+ stained cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Necessary Imports\n",
    "import sys\n",
    "sys.path.append(\"../DISF/python3/\")\n",
    "sys.path.append(\"../iDISF/python3/\")\n",
    "sys.path.append(\"../\")\n",
    "from scripts.metrics import calculate_precision, calculate_recall, calculate_f1_score\n",
    "\n",
    "from idisf import iDISF_scribbles\n",
    "from disf import DISF_Superpixels\n",
    "from scripts.segmentation_utils import *\n",
    "from PIL import Image\n",
    "from scripts.utils import *\n",
    "from scripts.superpixel_treatment import *\n",
    "from ptk_code.utils import *\n",
    "from ptk_code.TBM_PLOT import batch_PLOT\n",
    "\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import joblib\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the params for all the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_ids(predictions, superpixel_indexes):\n",
    "    \"\"\"Creating a list with only the positively classified superpixel ids\"\"\"\n",
    "    positive_preds = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        if prediction == 1:\n",
    "            positive_preds.append(superpixel_indexes[i])\n",
    "    return positive_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_overlap_img(pred, gt):\n",
    "    \"\"\" Creates an overlapped visualization\n",
    "    bewtween the ground truth and the obtained prediction\"\"\"\n",
    "    pred_arr = np.asarray(pred)\n",
    "    gt_arr = np.asarray(gt)\n",
    "    binary_xor = cv2.bitwise_xor(pred_arr, gt_arr)\n",
    "    return binary_xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_positive_classification_visualization(tp_img, fp_img, ground_truth):\n",
    "    green = np.array([0, 255, 0])\n",
    "    blue = np.array([0, 255, 0])\n",
    "    tp_img_colored = np.int32(change_color(tp_img, green))\n",
    "    fp_img_colored = np.int32(change_color(fp_img, blue))\n",
    "    ov_img = get_overlap_img(tp_img_colored, ground_truth)\n",
    "    ov_img = get_overlap_img(ov_img, fp_img_colored)\n",
    "    return ov_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(classifier,input_batch: list[np.array], n_masses:int) -> list[int]:\n",
    "    \"\"\"\n",
    "    Applies the TBM transform and predicts on the dataset\n",
    "    \"\"\"\n",
    "    # Loading the reference dataset\n",
    "    dataset = 'immuno_cells'\n",
    "    train_dir = '../data/'+dataset+'/training/'\n",
    "    (reference_x, y_train) = load_image_data(train_dir)\n",
    "    # Obtaining the test dataset\n",
    "    x_input = np.array([np.float64(rgb2gray(datapoint)) for datapoint in input_batch])\n",
    "    # Applying transform\n",
    "    batch_plot = batch_PLOT(Nmasses = n_masses)\n",
    "    x_template=np.mean(reference_x,axis=0)\n",
    "    reference_x_hat, x_input_hat, Pl_tem, P_tem = batch_plot.forward_seq(reference_x, x_input, x_template)\n",
    "    # Making predictions\n",
    "    preds = classifier.predict(x_input_hat)\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_superpixels(ids, superpixels):\n",
    "    \"\"\"Applies the superpixel filter by color mean thresholding\"\"\"\n",
    "    filtered_ids= []\n",
    "    filtered_superpixels = []\n",
    "    red_channel_mean_threshold = 130 \n",
    "    green_channel_mean_threshold = 90 \n",
    "    blue_channel_mean_threshold = 80 \n",
    "    for id, superpixel in zip(ids, superpixels):\n",
    "        red_channel_mean = sum(np.unique(superpixel[:,:,0])) / len(np.unique(superpixel[:,:,0]))\n",
    "        green_channel_mean = sum(np.unique(superpixel[:,:,1])) / len(np.unique(superpixel[:,:,1]))\n",
    "        blue_channel_mean = sum(np.unique(superpixel[:,:,2])) / len(np.unique(superpixel[:,:,2]))\n",
    "        if red_channel_mean < red_channel_mean_threshold and  green_channel_mean < green_channel_mean_threshold and blue_channel_mean < blue_channel_mean_threshold:\n",
    "            filtered_superpixels.append(superpixel)\n",
    "            filtered_ids.append(id)\n",
    "    return filtered_ids, filtered_superpixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obtain_fltered_superpixels(img, label_img):\n",
    "    # Obtaining the ids of the generated superpixels\n",
    "    superpixel_ids = np.unique(label_img)\n",
    "    superpixel_ids = superpixel_ids[1:] # Excluding the first empty superpixel\n",
    "\n",
    "    segmented_superpixels = []\n",
    "    segmented_superpixels_ids = []\n",
    "\n",
    "\n",
    "    for superpixel_id in superpixel_ids:\n",
    "        superpixel_img = get_superpixel_img(label_img, superpixel_id)\n",
    "        cropped_original_img,cropped_superpixel_img = get_cropped_superpixel_img(img, superpixel_img)\n",
    "        segmented = apply_mask(cropped_original_img, cropped_superpixel_img)\n",
    "        segmented_superpixels.append(segmented)\n",
    "        segmented_superpixels_ids.append(superpixel_id)\n",
    "\n",
    "    filtered_ids, filtered_superpixels = filter_superpixels(segmented_superpixels_ids, segmented_superpixels)\n",
    "    return filtered_ids, filtered_superpixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(plot_ns_model,superpixels,ids,n_masses= 300, num_of_tries=5):\n",
    "    higher_num_of_predictions = 0\n",
    "    positive_ids = []\n",
    "    all_predictions = []\n",
    "    for i in range(num_of_tries):\n",
    "        current_positive_ids = []\n",
    "        # Obtainig the predictions on the dataset\n",
    "        predictions = get_predictions(plot_ns_model,superpixels, n_masses)\n",
    "        # Obtaining only the ids that were classified positively\n",
    "        current_positive_ids = get_positive_ids(predictions, ids)\n",
    "        all_predictions.append(current_positive_ids)\n",
    "        if len(current_positive_ids) > higher_num_of_predictions:\n",
    "            higher_num_of_predictions = len(current_positive_ids)\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DISF_TBM_CELLS(img, num_init_seeds=7000, num_final_superpixels = 4000, n_masses = 300, num_of_tries = 5):\n",
    "    superpixel_label_img, border_img = DISF_Superpixels(img, num_init_seeds, num_final_superpixels)\n",
    "    label_img = superpixel_label_img.copy()\n",
    "    # Loading the classifier weights\n",
    "    plot_ns_model = joblib.load('../checkpoints/best.pkl')\n",
    "    ids, superpixels= obtain_fltered_superpixels(img, label_img)\n",
    "    all_predictions = make_predictions(plot_ns_model, superpixels, ids, n_masses, num_of_tries)\n",
    "    reconstructed_imgs = [get_reconstructed_image(label_img, all_predictions[i]) for i in range(len(all_predictions))]\n",
    "    prediction_amounts = [len(pred) for pred in all_predictions]\n",
    "    final_prediction_img = reconstructed_imgs[prediction_amounts.index(max(prediction_amounts))]\n",
    "    final_prediction_img = np.uint8(final_prediction_img)\n",
    "    return final_prediction_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Amount of objects on the ground truth: 158\n",
      "True Positive: 134\n",
      "False Negative: 23\n",
      "False Positive: 13\n",
      "Precision: 0.91\n",
      "Recall: 0.85\n",
      "F1-Score0.88\n"
     ]
    }
   ],
   "source": [
    "input_img = '2.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(apply_open(true_positive_img))[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Amount of objects on the ground truth: 117\n",
      "True Positive: 105\n",
      "False Negative: 16\n",
      "False Positive: 24\n",
      "Precision: 0.81\n",
      "Recall: 0.87\n",
      "F1-Score0.84\n"
     ]
    }
   ],
   "source": [
    "input_img = '3.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(true_positive_img)[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Amount of objects on the ground truth: 95\n",
      "True Positive: 77\n",
      "False Negative: 34\n",
      "False Positive: 4\n",
      "Precision: 0.95\n",
      "Recall: 0.69\n",
      "F1-Score0.8\n"
     ]
    }
   ],
   "source": [
    "input_img = '4.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(true_positive_img)[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n",
      "Len basis: 30\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <i4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/tcc/TBMCells/ptk_veenv/lib/python3.10/site-packages/PIL/Image.py:3130\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3129\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3130\u001b[0m     mode, rawmode \u001b[38;5;241m=\u001b[39m \u001b[43m_fromarray_typemap\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtypekey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3131\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mKeyError\u001b[0m: ((1, 1, 3), '<i4')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 21\u001b[0m\n\u001b[1;32m     15\u001b[0m comparison_ovl_img \u001b[38;5;241m=\u001b[39m get_positive_classification_visualization(\n\u001b[1;32m     16\u001b[0m     true_positive_img,\n\u001b[1;32m     17\u001b[0m     false_positive_img,\n\u001b[1;32m     18\u001b[0m     gt\n\u001b[1;32m     19\u001b[0m )\n\u001b[1;32m     20\u001b[0m Image\u001b[38;5;241m.\u001b[39mfromarray(segmentation)\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../quick_results/segmentation/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_img\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfromarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcomparison_ovl_img\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../quick_results/overlap/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_img\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAmount of objects on the ground truth: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mgt_obj_count\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTrue Positive: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrue_positive\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/tcc/TBMCells/ptk_veenv/lib/python3.10/site-packages/PIL/Image.py:3134\u001b[0m, in \u001b[0;36mfromarray\u001b[0;34m(obj, mode)\u001b[0m\n\u001b[1;32m   3132\u001b[0m         typekey_shape, typestr \u001b[38;5;241m=\u001b[39m typekey\n\u001b[1;32m   3133\u001b[0m         msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot handle this data type: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypekey_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtypestr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 3134\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m   3135\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3136\u001b[0m     rawmode \u001b[38;5;241m=\u001b[39m mode\n",
      "\u001b[0;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <i4"
     ]
    }
   ],
   "source": [
    "input_img = '5.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(true_positive_img)[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = '6.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(true_positive_img)[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "print(f\"Amount of objects on the ground truth: {gt_obj_count}\")\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = '7.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(true_positive_img)[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "print(f\"Amount of objects on the ground truth: {gt_obj_count}\")\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = '8.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(true_positive_img)[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "print(f\"Amount of objects on the ground truth: {gt_obj_count}\")\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = '9.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(true_positive_img)[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "print(f\"Amount of objects on the ground truth: {gt_obj_count}\")\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = '10.png'\n",
    "img = np.array(Image.open(f\"../data/cells_dataset/original/{input_img}\"), dtype= 'int32')\n",
    "gt = np.array(Image.open(f\"../data/cells_dataset/labels/{input_img}\"), dtype = 'int32')\n",
    "segmentation = DISF_TBM_CELLS(img)\n",
    "\n",
    "gray_gt = cv2.cvtColor(np.uint8(gt), cv2.COLOR_RGB2GRAY)\n",
    "true_positive_img = cv2.bitwise_and(segmentation, gray_gt)\n",
    "false_negative_img = apply_open(cv2.bitwise_xor(gray_gt, true_positive_img))\n",
    "false_positive_img = apply_open(cv2.bitwise_xor(segmentation, true_positive_img))\n",
    "# Obtaining the object count on each image\n",
    "gt_obj_count = cv2.connectedComponents(gray_gt)[0]\n",
    "true_positive =cv2.connectedComponents(true_positive_img)[0]\n",
    "false_negative = cv2.connectedComponents(false_negative_img)[0]\n",
    "false_positive = cv2.connectedComponents(false_positive_img)[0]\n",
    "comparison_ovl_img = get_positive_classification_visualization(\n",
    "    true_positive_img,\n",
    "    false_positive_img,\n",
    "    gt\n",
    ")\n",
    "Image.fromarray(segmentation).save(f'../quick_results/segmentation/{input_img}')\n",
    "Image.fromarray(comparison_ovl_img.astype('uint8')).save(f'../quick_results/overlap/{input_img}')\n",
    "print(f\"Amount of objects on the ground truth: {gt_obj_count}\")\n",
    "print(f\"True Positive: {true_positive}\")\n",
    "print(f\"False Negative: {false_negative}\")\n",
    "print(f\"False Positive: {false_positive}\")\n",
    "precision = round(calculate_precision(true_positive, false_positive),2)\n",
    "recall = round(calculate_recall(true_positive, false_negative), 2)\n",
    "f1_score = round(calculate_f1_score(precision, recall), 2)\n",
    "print(f\"Precision: {precision}\\nRecall: {recall}\\nF1-Score{f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
